---

# **YOLO Domain â€“ Satellite Imagery (DOTA)**

<p align="center">
  <img src="https://img.shields.io/badge/YOLO-v8%20%7C%20v9%20%7C%20v10-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/Python-3.10+-green?style=flat-square" />
  <img src="https://img.shields.io/badge/Dataset-DOTA-red?style=flat-square" />
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square" />
  <img src="https://img.shields.io/badge/Status-Active-success?style=flat-square" />
</p>

---

This repository provides a **complete, end-to-end preprocessing and training pipeline** for building **YOLO-based object detection models** on **high-resolution satellite imagery**, using the **DOTA (Dataset for Object Detection in Aerial Images)** dataset.

The objective is simple and strict:

> **Build a clean, reproducible, domain-specific YOLO model for satellite / aerial imagery.**

This work is part of the **YOLO Domain Hub initiative**, focusing on **correct geometry, scalable preprocessing, and reliable benchmarking**.

---

## ğŸš€ Overview

Satellite and aerial imagery introduce challenges that generic datasets do not:

* Extremely large images (3kâ€“6k resolution)
* Tiny, dense objects
* Large-scale variation
* Heavy background clutter
* Oriented objects (OBB annotations)

This repository addresses these challenges by enforcing a **strict preprocessing pipeline** *before* training YOLO models.

---

## ğŸ“¦ Dataset: DOTA (v1.0)

**DOTA (Dataset for Object Detection in Aerial Images)** provides:

* High-resolution aerial images
* Oriented bounding box (OBB) annotations
* 15 object categories
* Diverse scenes (urban, ports, airports, industrial zones)

Official dataset page:

```
https://captain-whu.github.io/DOTA/
```

This repository currently supports **DOTA v1.0**.

---

## ğŸ” Data Processing Pipeline

DOTA annotations are **not YOLO-compatible**.
This repository converts them through a **multi-stage, geometry-safe pipeline**.

---

### 1ï¸âƒ£ DOTA â†’ YOLO Label Conversion

* Converts OBB (4-point polygons) â†’ HBB (horizontal bounding boxes)
* Preserves floating-point precision
* Drops difficult objects (configurable)
* Outputs standard YOLO format

YOLO label format:

```
<class_id> <x_center> <y_center> <width> <height>
```

---

### 2ï¸âƒ£ Image Tiling (Mandatory)

DOTA images are extremely large and **cannot be trained directly**.

Tiling parameters:

* Tile size: **1024 Ã— 1024**
* Overlap: **200 px**
* Bounding boxes are clipped and adjusted per tile
* Very small boxes are filtered to reduce noise

This step is **non-optional** for DOTA-scale imagery.

---

### 3ï¸âƒ£ Train / Validation Split

* Split is performed **after tiling**
* Deterministic (seeded)
* Ensures imageâ€“label alignment
* Produces YOLO-compatible directory layout

Final dataset structure:

```
dataset/
â””â”€â”€ tiles_split/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â””â”€â”€ labels/
        â”œâ”€â”€ train/
        â””â”€â”€ val/
```

---

### 4ï¸âƒ£ Visual Sanity Checking

Before training, labels are **visually inspected**:

* Bounding boxes are drawn on images
* Checked before and after tiling
* Prevents silent geometry errors

This step ensures **training correctness before GPU time is spent**.

---

## ğŸ§  Processing Philosophy (Important)

* âŒ No resizing full images before tiling

* âŒ No mixing DOTA and YOLO labels

* âŒ No training without visual checks

* âœ… Convert â†’ tile â†’ split â†’ verify â†’ train

* âœ… Skip invalid data aggressively

* âœ… Protect valid annotations

---

## ğŸ—ï¸ Training Pipeline

Baseline YOLO training example:

```bash
yolo detect train \
  model=yolov8s.pt \
  data=data.yaml \
  imgsz=640 \
  epochs=100
```

Experiments are conducted across:

### âœ” YOLO Versions

* YOLOv8
* YOLOv9
* YOLOv10

### âœ” Model Sizes

* n / s / m / l / x

### âœ” Training Parameters

* Image size
* Batch size
* Epochs
* Augmentations

The goal is **clean benchmarking**, not leaderboard chasing.

---

## ğŸ“Š Evaluation Metrics

For every trained model, the following are recorded:

* **mAP50â€“95** (primary metric)
* **mAP50**
* **Precision**
* **Recall**
* **Per-class performance**
* **Model size & YOLO version**
* **Training configuration**

This ensures **reproducible and comparable results**.

---

## ğŸ“‚ Repository Structure

```
YOLO Domain Satellite Imagery/
â”œâ”€â”€ data/                     # dataset.yaml, class mappings
â”œâ”€â”€ dataset/                  # processed YOLO-ready dataset
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dota/                 # Core DOTA processing modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ classes.py        # DOTA class definitions
â”‚   â”‚   â”œâ”€â”€ converter.py      # DOTA â†’ YOLO conversion logic
â”‚   â”‚   â”œâ”€â”€ datastats.py      # Dataset statistics & analysis
â”‚   â”‚   â”œâ”€â”€ tiler.py          # Image tiling logic
â”‚   â”‚   â””â”€â”€ visualizer.py     # Visual sanity checker
â”‚   â”‚
â”‚   â”œâ”€â”€ converter_dota.py     # Conversion runner
â”‚   â”œâ”€â”€ datastats_dota.py     # Statistics runner
â”‚   â”œâ”€â”€ tiler_dota.py         # Tiling runner
â”‚   â””â”€â”€ visualizer_dota.py    # Visualization runner
â”‚
â”œâ”€â”€ models/                   # Trained model weights
â”œâ”€â”€ notebooks/                # Experiments & analysis
â””â”€â”€ README.md
```

---

## âš™ï¸ Environment Setup

Core dependencies:

```bash
pip install ultralytics
pip install numpy pillow opencv-python
```

Recommended utilities:

```bash
pip install matplotlib tqdm
```

---

## ğŸ“œ License

* **Code**: MIT License
* **Dataset**: DOTA License (dataset usage restrictions apply)
* **Training Framework**: Ultralytics YOLO License

This repository is intended for **open-source research and reproducible model development**.

---

## ğŸ§­ Project Status

* âœ… DOTA â†’ YOLO conversion
* âœ… Image tiling
* âœ… Train/val split
* âœ… Visual sanity checks
* â³ Baseline YOLO training
* â³ Benchmarking & reporting

---

## ğŸ§© YOLO Domain Hub Alignment

This repository is designed to integrate cleanly into the **YOLO Domain Hub**:

* Clear dataset preprocessing
* Reproducible metrics
* Transparent training setup
* Domain-specific focus

---
